{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RumoisteinKartenspiel/Bioinformatic_course_2022_project/blob/main/Selective_RFdiff_with_Backup.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSgCPxIZ1T_A"
      },
      "source": [
        "#**RFdiffusion with Google Drive integration**\n",
        "RFdiffusion is a method for structure generation, with or without conditional information (a motif, target etc). It can perform a whole range of protein design challenges as we have outlined in the RFdiffusion [manuscript](https://www.biorxiv.org/content/10.1101/2022.12.09.519842v2).\n",
        "\n",
        "**<font color=\"red\">NOTE:</font>** This notebook is in development, we are still working on adding all the options from the manuscript above.\n",
        "\n",
        "For **instructions**, see end of Notebook.\n",
        "\n",
        "See [diffusion_foldcond](https://colab.research.google.com/github/sokrypton/ColabDesign/blob/v1.1.1/rf/examples/diffusion_foldcond.ipynb) for fold conditioning functionality.\n",
        "\n",
        "See [original version](https://colab.research.google.com/github/sokrypton/ColabDesign/blob/v1.1.1/rf/examples/diffusion_ori.ipynb) of this notebook (from 31Mar2023).\n",
        "\n",
        "***\n",
        "\n",
        "#Changes to original Colab\n",
        "Included  possibility to mount Google drive to backup the data during the run.\n",
        "- If run aborts after the RF diffusion step, just run all cells again **exept** \"Pdb file upload\" and \"run RFdiffusion to generate a backbone\"\n",
        "- The project name will be create a new folder in the drive with this name, please DO NOT leave spaces, if wished use underscore \"_\".\n",
        "- Setting the variable \"name\" in \"run RFdiffusion to generate a backbone\" will create a subfolder contianing all the information and data for this specific run, this allows also to design multiple proteins within one project.\n",
        "- For rerunning, **please note the \"name\" of the run you want to recreate**, this will be asked for input in \"Display 3D structure\" and \"Running ProteinMPNN\" interactivly. (Please look for it at the end of the cell, where the output is printed.)\n",
        "- Dont use spaces in project and run naming, will be repalced with \"_\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZQnHLuDCsZm",
        "outputId": "69aec0c2-0a1e-49e0-f5c5-f024375bf066"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "installing ColabDesign...\n",
            "downloading RFdiffusion params...\n",
            "CPU times: user 5.45 s, sys: 1.06 s, total: 6.5 s\n",
            "Wall time: 1min 16s\n"
          ]
        }
      ],
      "source": [
        "#@title setup dependencies and **RFdiffusion** (~2m)\n",
        "#@markdown Please also run this when restarting a run and skipping RF diffusion step, important parameter are defined and installed here.\n",
        "%%time\n",
        "import os, time, signal\n",
        "import sys, random, string, re\n",
        "if not os.path.isdir(\"params\"):\n",
        "  os.system(\"apt-get install aria2\")\n",
        "  os.system(\"mkdir params\")\n",
        "  # send param download into background\n",
        "  os.system(\"(\\\n",
        "  aria2c -q -x 16 https://files.ipd.uw.edu/krypton/schedules.zip; \\\n",
        "  aria2c -q -x 16 http://files.ipd.uw.edu/pub/RFdiffusion/6f5902ac237024bdd0c176cb93063dc4/Base_ckpt.pt; \\\n",
        "  aria2c -q -x 16 http://files.ipd.uw.edu/pub/RFdiffusion/e29311f6f1bf1af907f9ef9f44b8328b/Complex_base_ckpt.pt; \\\n",
        "  aria2c -q -x 16 http://files.ipd.uw.edu/pub/RFdiffusion/f572d396fae9206628714fb2ce00f72e/Complex_beta_ckpt.pt; \\\n",
        "  aria2c -q -x 16 https://storage.googleapis.com/alphafold/alphafold_params_2022-12-06.tar; \\\n",
        "  tar -xf alphafold_params_2022-12-06.tar -C params; \\\n",
        "  touch params/done.txt) &\")\n",
        "\n",
        "if not os.path.isdir(\"RFdiffusion\"):\n",
        "  print(\"installing RFdiffusion...\")\n",
        "  os.system(\"git clone https://github.com/sokrypton/RFdiffusion.git\")\n",
        "  os.system(\"pip install jedi omegaconf hydra-core icecream pyrsistent pynvml decorator\")\n",
        "  os.system(\"pip install git+https://github.com/NVIDIA/dllogger#egg=dllogger\")\n",
        "  # 17Mar2024: adding --no-dependencies to avoid installing nvidia-cuda-* dependencies\n",
        "  os.system(\"pip install --no-dependencies dgl==2.0.0 -f https://data.dgl.ai/wheels/cu121/repo.html\")\n",
        "  os.system(\"pip install --no-dependencies e3nn==0.3.3 opt_einsum_fx\")\n",
        "  os.system(\"cd RFdiffusion/env/SE3Transformer; pip install .\")\n",
        "  #os.system(\"wget -qnc https://files.ipd.uw.edu/krypton/ananas\")\n",
        "  #os.system(\"chmod +x ananas\")\n",
        "\n",
        "if not os.path.isdir(\"colabdesign\"):\n",
        "  print(\"installing ColabDesign...\")\n",
        "  os.system(\"pip -q install git+https://github.com/sokrypton/ColabDesign.git@v1.1.1\")\n",
        "  os.system(\"ln -s /usr/local/lib/python3.*/dist-packages/colabdesign colabdesign\")\n",
        "\n",
        "if not os.path.isdir(\"RFdiffusion/models\"):\n",
        "  print(\"downloading RFdiffusion params...\")\n",
        "  os.system(\"mkdir RFdiffusion/models\")\n",
        "  models = [\"Base_ckpt.pt\",\"Complex_base_ckpt.pt\"]\n",
        "  for m in models:\n",
        "    while os.path.isfile(f\"{m}.aria2\"):\n",
        "      time.sleep(5)\n",
        "  os.system(f\"mv {' '.join(models)} RFdiffusion/models\")\n",
        "  os.system(\"unzip schedules.zip; rm schedules.zip\")\n",
        "\n",
        "if 'RFdiffusion' not in sys.path:\n",
        "  os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
        "  sys.path.append('RFdiffusion')\n",
        "\n",
        "from google.colab import files\n",
        "import json\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, HTML\n",
        "import ipywidgets as widgets\n",
        "import py3Dmol\n",
        "import os\n",
        "import shutil\n",
        "try:\n",
        "    import Bio\n",
        "except ImportError:\n",
        "    !pip install biopython\n",
        "    import Bio\n",
        "import Bio.PDB\n",
        "from Bio import PDB\n",
        "import subprocess\n",
        "\n",
        "\n",
        "from inference.utils import parse_pdb\n",
        "from colabdesign.rf.utils import get_ca\n",
        "from colabdesign.rf.utils import fix_contigs, fix_partial_contigs, fix_pdb, sym_it\n",
        "from colabdesign.shared.protein import pdb_to_string\n",
        "from colabdesign.shared.plot import plot_pseudo_3D\n",
        "\n",
        "def get_pdb(pdb_code=None):\n",
        "\n",
        "  directory_path = path + \"/input_pdbs\"\n",
        "    # Check if the directory already exists\n",
        "  if not os.path.exists(directory_path):\n",
        "    # If it doesn't exist, create the directory\n",
        "    os.makedirs(directory_path)\n",
        "\n",
        "    # Specify the directory path\n",
        "    print()\n",
        "    if pdb_code is None or pdb_code == \"\" or pdb_code == \"upload\":\n",
        "        # Use the file upload widget to upload PDB files\n",
        "        uploaded = files.upload()\n",
        "\n",
        "        print(\"Double check your input please, especially if the selected residue number are matching to your target residues!\")\n",
        "        # Load the pdb file\n",
        "        parser = Bio.PDB.PDBParser()\n",
        "        structure = parser.get_structure(\"input_pdb\", list(uploaded.keys())[0])\n",
        "\n",
        "        # Iterate over the structure\n",
        "        for model in structure:\n",
        "            for chain in model:\n",
        "                # Get the chain ID\n",
        "                chain_id = chain.id\n",
        "\n",
        "                # Initialize variables for the current chain\n",
        "                chain_length = 0\n",
        "                residues = []\n",
        "\n",
        "                # Iterate over the residues in the chain\n",
        "                for residue in chain:\n",
        "                    # Increment the chain length\n",
        "                    chain_length += 1\n",
        "\n",
        "                    # Add residue information to the list\n",
        "                    residue_name = residue.resname\n",
        "                    residue_number = residue.id[1]\n",
        "                    residues.append(f\"{residue_name}{residue_number}\")\n",
        "\n",
        "                # Print the chain length and all residues\n",
        "                print(\"Here are some information about your input file:\")\n",
        "                print(f\"Chain {chain_id}:\")\n",
        "                print(f\"\\tLength: {chain_length}\")\n",
        "                print(f\"\\tResidues: {' '.join(residues)}\")\n",
        "\n",
        "        # Move the uploaded files to the input_pdbs directory\n",
        "        for filename in uploaded.keys():\n",
        "            source_path = filename\n",
        "            destination_path = os.path.join(directory_path, filename)\n",
        "            shutil.copy2(source_path, destination_path)\n",
        "\n",
        "        return destination_path\n",
        "\n",
        "    elif os.path.isfile(os.path.join(directory_path, pdb_code)):\n",
        "        return os.path.join(directory_path, pdb_code)\n",
        "\n",
        "\n",
        "def run_ananas(pdb_str, path, sym=None):\n",
        "  pdb_filename = f\"{path}/ananas_input.pdb\"\n",
        "  out_filename = f\"{path}/ananas.json\"\n",
        "  with open(pdb_filename,\"w\") as handle:\n",
        "    handle.write(pdb_str)\n",
        "\n",
        "  cmd = f\"./ananas {pdb_filename} -u -j {out_filename}\"\n",
        "  if sym is None: os.system(cmd)\n",
        "  else: os.system(f\"{cmd} {sym}\")\n",
        "\n",
        "  # parse results\n",
        "  try:\n",
        "    out = json.loads(open(out_filename,\"r\").read())\n",
        "    results,AU = out[0], out[-1][\"AU\"]\n",
        "    group = AU[\"group\"]\n",
        "    chains = AU[\"chain names\"]\n",
        "    rmsd = results[\"Average_RMSD\"]\n",
        "    print(f\"AnAnaS detected {group} symmetry at RMSD:{rmsd:.3}\")\n",
        "\n",
        "    C = np.array(results['transforms'][0]['CENTER'])\n",
        "    A = [np.array(t[\"AXIS\"]) for t in results['transforms']]\n",
        "\n",
        "    # apply symmetry and filter to the asymmetric unit\n",
        "    new_lines = []\n",
        "    for line in pdb_str.split(\"\\n\"):\n",
        "      if line.startswith(\"ATOM\"):\n",
        "        chain = line[21:22]\n",
        "        if chain in chains:\n",
        "          x = np.array([float(line[i:(i+8)]) for i in [30,38,46]])\n",
        "          if group[0] == \"c\":\n",
        "            x = sym_it(x,C,A[0])\n",
        "          if group[0] == \"d\":\n",
        "            x = sym_it(x,C,A[1],A[0])\n",
        "          coord_str = \"\".join([\"{:8.3f}\".format(a) for a in x])\n",
        "          new_lines.append(line[:30]+coord_str+line[54:])\n",
        "      else:\n",
        "        new_lines.append(line)\n",
        "    return results, \"\\n\".join(new_lines)\n",
        "\n",
        "  except:\n",
        "    return None, pdb_str\n",
        "\n",
        "def run(command, steps, num_designs=1, visual=\"none\"):\n",
        "\n",
        "  def run_command_and_get_pid(command):\n",
        "    pid_file = '/dev/shm/pid'\n",
        "    os.system(f'nohup {command} > /dev/null & echo $! > {pid_file}')\n",
        "    with open(pid_file, 'r') as f:\n",
        "      pid = int(f.read().strip())\n",
        "    os.remove(pid_file)\n",
        "    return pid\n",
        "  def is_process_running(pid):\n",
        "    try:\n",
        "      os.kill(pid, 0)\n",
        "    except OSError:\n",
        "      return False\n",
        "    else:\n",
        "      return True\n",
        "\n",
        "  run_output = widgets.Output()\n",
        "  progress = widgets.FloatProgress(min=0, max=1, description='running', bar_style='info')\n",
        "  display(widgets.VBox([progress, run_output]))\n",
        "\n",
        "  # clear previous run\n",
        "  for n in range(steps):\n",
        "    if os.path.isfile(f\"/dev/shm/{n}.pdb\"):\n",
        "      os.remove(f\"/dev/shm/{n}.pdb\")\n",
        "\n",
        "  pid = run_command_and_get_pid(command)\n",
        "  try:\n",
        "    fail = False\n",
        "    for _ in range(num_designs):\n",
        "\n",
        "      # for each step check if output generated\n",
        "      for n in range(steps):\n",
        "        wait = True\n",
        "        while wait and not fail:\n",
        "          time.sleep(0.1)\n",
        "          if os.path.isfile(f\"/dev/shm/{n}.pdb\"):\n",
        "            pdb_str = open(f\"/dev/shm/{n}.pdb\").read()\n",
        "            if pdb_str[-3:] == \"TER\":\n",
        "              wait = False\n",
        "            elif not is_process_running(pid):\n",
        "              fail = True\n",
        "          elif not is_process_running(pid):\n",
        "            fail = True\n",
        "\n",
        "        if fail:\n",
        "          progress.bar_style = 'danger'\n",
        "          progress.description = \"failed\"\n",
        "          break\n",
        "\n",
        "        else:\n",
        "          progress.value = (n+1) / steps\n",
        "          if visual != \"none\":\n",
        "            with run_output:\n",
        "              run_output.clear_output(wait=True)\n",
        "              if visual == \"image\":\n",
        "                xyz, bfact = get_ca(f\"/dev/shm/{n}.pdb\", get_bfact=True)\n",
        "                fig = plt.figure()\n",
        "                fig.set_dpi(100);fig.set_figwidth(6);fig.set_figheight(6)\n",
        "                ax1 = fig.add_subplot(111);ax1.set_xticks([]);ax1.set_yticks([])\n",
        "                plot_pseudo_3D(xyz, c=bfact, cmin=0.5, cmax=0.9, ax=ax1)\n",
        "                plt.show()\n",
        "              if visual == \"interactive\":\n",
        "                view = py3Dmol.view(js='https://3dmol.org/build/3Dmol.js')\n",
        "                view.addModel(pdb_str,'pdb')\n",
        "                view.setStyle({'cartoon': {'colorscheme': {'prop':'b','gradient': 'roygb','min':0.5,'max':0.9}}})\n",
        "                view.zoomTo()\n",
        "                view.show()\n",
        "        if os.path.exists(f\"/dev/shm/{n}.pdb\"):\n",
        "          os.remove(f\"/dev/shm/{n}.pdb\")\n",
        "      if fail:\n",
        "        progress.bar_style = 'danger'\n",
        "        progress.description = \"failed\"\n",
        "        break\n",
        "\n",
        "    while is_process_running(pid):\n",
        "      time.sleep(0.1)\n",
        "\n",
        "  except KeyboardInterrupt:\n",
        "    os.kill(pid, signal.SIGTERM)\n",
        "    progress.bar_style = 'danger'\n",
        "    progress.description = \"stopped\"\n",
        "\n",
        "def run_diffusion(contigs, path, pdb=None, iterations=50,\n",
        "                  symmetry=\"none\", order=1, hotspot=None,\n",
        "                  chains=None, add_potential=False,\n",
        "                  num_designs=1, visual=\"none\", name=\"test\"):\n",
        "\n",
        "  full_path = f\"{path}\"\n",
        "  os.makedirs(full_path, exist_ok=True)\n",
        "  opts = [f\"inference.output_prefix={full_path}\",\n",
        "          f\"inference.num_designs={num_designs}\"]\n",
        "\n",
        "  if chains == \"\": chains = None\n",
        "\n",
        "  # determine symmetry type\n",
        "  if symmetry in [\"auto\",\"cyclic\",\"dihedral\"]:\n",
        "    if symmetry == \"auto\":\n",
        "      sym, copies = None, 1\n",
        "    else:\n",
        "      sym, copies = {\"cyclic\":(f\"c{order}\",order),\n",
        "                     \"dihedral\":(f\"d{order}\",order*2)}[symmetry]\n",
        "  else:\n",
        "    symmetry = None\n",
        "    sym, copies = None, 1\n",
        "\n",
        "  # determine mode\n",
        "  contigs = contigs.replace(\",\",\" \").replace(\":\",\" \").split()\n",
        "  is_fixed, is_free = False, False\n",
        "  fixed_chains = []\n",
        "  for contig in contigs:\n",
        "    for x in contig.split(\"/\"):\n",
        "      a = x.split(\"-\")[0]\n",
        "      if a[0].isalpha():\n",
        "        is_fixed = True\n",
        "        if a[0] not in fixed_chains:\n",
        "          fixed_chains.append(a[0])\n",
        "      if a.isnumeric():\n",
        "        is_free = True\n",
        "  if len(contigs) == 0 or not is_free:\n",
        "    mode = \"partial\"\n",
        "  elif is_fixed:\n",
        "    mode = \"fixed\"\n",
        "  else:\n",
        "    mode = \"free\"\n",
        "\n",
        "  # fix input contigs\n",
        "  if mode in [\"partial\",\"fixed\"]:\n",
        "    pdb_str = pdb_to_string(get_pdb(pdb), chains=chains)\n",
        "    if symmetry == \"auto\":\n",
        "      a, pdb_str = run_ananas(pdb_str, path)\n",
        "      if a is None:\n",
        "        print(f'ERROR: no symmetry detected')\n",
        "        symmetry = None\n",
        "        sym, copies = None, 1\n",
        "      else:\n",
        "        if a[\"group\"][0] == \"c\":\n",
        "          symmetry = \"cyclic\"\n",
        "          sym, copies = a[\"group\"], int(a[\"group\"][1:])\n",
        "        elif a[\"group\"][0] == \"d\":\n",
        "          symmetry = \"dihedral\"\n",
        "          sym, copies = a[\"group\"], 2 * int(a[\"group\"][1:])\n",
        "        else:\n",
        "          print(f'ERROR: the detected symmetry ({a[\"group\"]}) not currently supported')\n",
        "          symmetry = None\n",
        "          sym, copies = None, 1\n",
        "\n",
        "    elif mode == \"fixed\":\n",
        "      pdb_str = pdb_to_string(pdb_str, chains=fixed_chains)\n",
        "\n",
        "    pdb_filename = f\"{full_path}/input.pdb\"\n",
        "    with open(pdb_filename, \"w\") as handle:\n",
        "      handle.write(pdb_str)\n",
        "\n",
        "    parsed_pdb = parse_pdb(pdb_filename)\n",
        "    opts.append(f\"inference.input_pdb={pdb_filename}\")\n",
        "    if mode in [\"partial\"]:\n",
        "      iterations = int(80 * (iterations / 200))\n",
        "      opts.append(f\"diffuser.partial_T={iterations}\")\n",
        "      contigs = fix_partial_contigs(contigs, parsed_pdb)\n",
        "    else:\n",
        "      opts.append(f\"diffuser.T={iterations}\")\n",
        "      contigs = fix_contigs(contigs, parsed_pdb)\n",
        "  else:\n",
        "    opts.append(f\"diffuser.T={iterations}\")\n",
        "    parsed_pdb = None\n",
        "    contigs = fix_contigs(contigs, parsed_pdb)\n",
        "\n",
        "  if hotspot is not None and hotspot != \"\":\n",
        "    opts.append(f\"ppi.hotspot_res=[{hotspot}]\")\n",
        "\n",
        "  # setup symmetry\n",
        "  if sym is not None:\n",
        "    sym_opts = [\"--config-name symmetry\", f\"inference.symmetry={sym}\"]\n",
        "    if add_potential:\n",
        "      sym_opts += [\"'potentials.guiding_potentials=[\\\"type:olig_contacts,weight_intra:1,weight_inter:0.1\\\"]'\",\n",
        "                   \"potentials.olig_intra_all=True\",\"potentials.olig_inter_all=True\",\n",
        "                   \"potentials.guide_scale=2\",\"potentials.guide_decay=quadratic\"]\n",
        "    opts = sym_opts + opts\n",
        "    contigs = sum([contigs] * copies,[])\n",
        "\n",
        "  opts.append(f\"'contigmap.contigs=[{' '.join(contigs)}]'\")\n",
        "  opts += [\"inference.dump_pdb=True\",\"inference.dump_pdb_path='/dev/shm'\"]\n",
        "\n",
        "  print(\"mode:\", mode)\n",
        "  print(\"output:\", full_path)\n",
        "  print(\"contigs:\", contigs)\n",
        "\n",
        "  opts_str = \" \".join(opts)\n",
        "  cmd = f\"./RFdiffusion/run_inference.py {opts_str}\"\n",
        "  print(cmd)\n",
        "\n",
        "  # RUN\n",
        "  run(cmd, iterations, num_designs, visual=visual)\n",
        "\n",
        "  # fix pdbs\n",
        "  cut_of_path = path[:-len(name)]\n",
        "\n",
        "  for n in range(num_designs):\n",
        "    pdbs = [f\"{cut_of_path}traj/{name}_{n}_pX0_traj.pdb\",\n",
        "            f\"{cut_of_path}traj/{name}_{n}_Xt-1_traj.pdb\",\n",
        "            f\"{full_path}_{n}.pdb\"]\n",
        "    for pdb in pdbs:\n",
        "      with open(pdb,\"r\") as handle: pdb_str = handle.read()\n",
        "      with open(pdb,\"w\") as handle: handle.write(fix_pdb(pdb_str, contigs))\n",
        "\n",
        "\n",
        "  return contigs, copies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGN2ZijtpxRy",
        "outputId": "e02d9364-8f59-4b5f-d5f8-123c5f17b6cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your first name (always enter it the same way!): Noah\n",
            "Mounted at /content/cloud_drive\n"
          ]
        }
      ],
      "source": [
        "#@title Get Access to Google Drive or run local { vertical-output: true }\n",
        "import os\n",
        "from datetime import datetime\n",
        "#@markdown - **Attenion** if run locally, if runtime disconnects (highly likely) all data ist lost and all predicitons start from first entry!\n",
        "#@markdown - **Recommended** run on Google drive to backup the data directly. (Untick local run)\n",
        "#@markdown - Unfinished RF diffusion runs will still have to be rerun, but partial data can be recovered.\n",
        "#@markdown - Disabeling local run also allows to use old RFdiff results to just genereate more Sequences with PorteinMPNN\"\n",
        "\n",
        "local_run = False # @param {type:\"boolean\"}\n",
        "#@markdown Google drive is default, only activate local if necessary\n",
        "\n",
        "# Specify the base directory where you want to create the directories\n",
        "project_directory_name = \"Test\" # @param {type:\"string\"}\n",
        "project_directory_name = project_directory_name.replace(\" \", \"_\")\n",
        "\n",
        "local_directory = '/content/' + project_directory_name\n",
        "drive_directory = local_directory\n",
        "\n",
        "# Add current date to the filename\n",
        "current_date = datetime.now().strftime('%y%m%d')\n",
        "\n",
        "\n",
        "local_directory = f'/content/{current_date}' + project_directory_name\n",
        "drive_directory = local_directory\n",
        "if 'home_dir_user' not in globals():\n",
        "    home_dir_user = input(\"Enter your first name (always enter it the same way!): \")\n",
        "if not local_run:\n",
        "  #@title only needed if run on Google cloude computing\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/cloud_drive',force_remount=True)\n",
        "  drive_directory = f\"/content/cloud_drive/MyDrive/{home_dir_user}/RFdiff/{current_date}_\" + project_directory_name\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "TuRUfQJZ4vkM"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "#@title run **RFdiffusion** to generate a backbone\n",
        "#@markdown  Can be skipped if already successfully run and only more sequences are to be designed with ProteinMPNN.\n",
        "name = \"full_rfdiff_result\"\n",
        "#@markdown Enter which part of the input schould be given into the model (leave empty to consider all input, used for partial diffusion)\n",
        "#@markdown - For Binder set like this: \"B10-196:60\", where chain B residue 10-160 defines the target, and we want a 60 aminoacid linker\n",
        "contigs = \"A1-198:65-75\" #@param {type:\"string\"}\n",
        "#@markdown - Run this cell, upload file will be shown at the bottom. It only accepts manually uploaded files to prevent input mistakes\n",
        "#@markdown - Double check your input please, especially if the selected residue number are matching to your target residues! Look at the output there the sequence with number is printed again.\n",
        "pdb = \"upload\"\n",
        "iterations = 25 #@param [\"25\", \"50\", \"100\", \"150\", \"200\"] {type:\"raw\"}\n",
        "#@markdown Set the hotspots like this: \"B76,B79,B113\" to select residue 76,79,113 of chain B as hotspot\n",
        "hotspot = \"A11,A13\" #@param {type:\"string\"}\n",
        "hotspot = hotspot.replace(\" \", \"\") #removes spaces from the hotspot input\n",
        "num_designs = 4 #@param [\"1\", \"2\", \"4\", \"8\", \"16\", \"32\", \"64\", \"128\"] {type:\"raw\"}\n",
        "visual = \"none\"\n",
        "symmetry = \"none\"\n",
        "order = 1\n",
        "chains = \"\"\n",
        "add_potential = False\n",
        "\n",
        "\n",
        "counter = 1\n",
        "\n",
        "while True:\n",
        "    # Generate the directory name with a counter\n",
        "    path = f\"{drive_directory}_RFdiff_run_{counter:03d}/{name}\"\n",
        "    # Check if the directory already exists\n",
        "    if not os.path.exists(path):\n",
        "        # If it doesn't exist, create the directory and break out of the loop\n",
        "        os.makedirs(path)\n",
        "        print(f\"Created result directory: {path}\")\n",
        "        break\n",
        "    counter += 1\n",
        "\n",
        "flags = {\"contigs\":contigs,\n",
        "         \"pdb\":pdb,\n",
        "         \"order\":order,\n",
        "         \"iterations\":iterations,\n",
        "         \"symmetry\":symmetry,\n",
        "         \"hotspot\":hotspot,\n",
        "         \"path\":path,\n",
        "         \"chains\":chains,\n",
        "         \"add_potential\":add_potential,\n",
        "         \"num_designs\":num_designs,\n",
        "         \"visual\":visual,\n",
        "         \"name\":name}\n",
        "\n",
        "for k,v in flags.items():\n",
        "  if isinstance(v,str):\n",
        "    flags[k] = v.replace(\"'\",\"\").replace('\"','')\n",
        "\n",
        "contigs, copies = run_diffusion(**flags)\n",
        "\n",
        "import pickle\n",
        "\n",
        "file_path = os.path.join(path, 'contig_variable.pkl')\n",
        "\n",
        "# Save the variable to the specified directory\n",
        "with open(file_path, 'wb') as file:\n",
        "    pickle.dump(contigs, file)\n",
        "\n",
        "file_path = os.path.join(path, 'copies_variable.pkl')\n",
        "\n",
        "# Save the variable to the specified directory\n",
        "with open(file_path, 'wb') as file:\n",
        "    pickle.dump(copies, file)\n",
        "\n",
        "file_path = os.path.join(path, 'num_designs_variable.pkl')\n",
        "\n",
        "# Save the variable to the specified directory\n",
        "with open(file_path, 'wb') as file:\n",
        "    pickle.dump(num_designs, file)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "wqEi03_qi_g2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "collapsed": true,
        "outputId": "d3c56726-7f62-4e77-a03e-130d10136d6b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'colabdesign'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-3eaa0e23478d>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdenoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdpi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcolabdesign\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshared\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpymol_color_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcolabdesign\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_ca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_Ls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmake_animation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstring\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mascii_uppercase\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mascii_lowercase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'colabdesign'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "#@title Display 3D structure {run: \"auto\"}\n",
        "animate = \"none\"\n",
        "color = \"plddt\"\n",
        "denoise = True\n",
        "dpi = 100\n",
        "from colabdesign.shared.plot import pymol_color_list\n",
        "from colabdesign.rf.utils import get_ca, get_Ls, make_animation\n",
        "from string import ascii_uppercase,ascii_lowercase\n",
        "alphabet_list = list(ascii_uppercase+ascii_lowercase)\n",
        "\n",
        "if not 'name' in globals():\n",
        "    print(\"You are trying to rerun this box without runnning RF diff first, please tick \\\"restarting_after_shutdown\\\".\")\n",
        "\n",
        "restarting_after_shutdown = False # @param {type:\"boolean\"}\n",
        "\n",
        "if restarting_after_shutdown:\n",
        "        import pickle\n",
        "        name = \"full_rfdiff_result\"\n",
        "\n",
        "        # Define the drive directory\n",
        "        home_directory = f\"/content/cloud_drive/MyDrive/{home_dir_user}/RFdiff/\"\n",
        "\n",
        "\n",
        "\n",
        "        # Get a list of all directories in the drive directory\n",
        "        all_dirs = [d for d in os.listdir(home_directory) if os.path.isdir(os.path.join(home_directory, d))]\n",
        "\n",
        "        # Display a numbered list of directories\n",
        "        print(\"Available Directories:\")\n",
        "        for i, d in enumerate(all_dirs, 1):\n",
        "              print(f\"[{i}] {d}\")\n",
        "\n",
        "          # Prompt the user to input a number\n",
        "        selected_number = input(\"Enter the number of the directory you want to select: \")\n",
        "\n",
        "          # Validate user input\n",
        "        try:\n",
        "              selected_number = int(selected_number)\n",
        "              if 1 <= selected_number <= len(all_dirs):\n",
        "                  selected_dir = all_dirs[selected_number - 1]\n",
        "                  print(f\"Selected directory: {selected_dir}\")\n",
        "              else:\n",
        "                  print(\"Invalid number. Please enter a valid number.\")\n",
        "        except ValueError:\n",
        "              print(\"Invalid input. Please enter a valid number.\")\n",
        "\n",
        "        file_path_1 = os.path.join(f\"{home_directory}{selected_dir}\", name, 'contig_variable.pkl')\n",
        "        file_path_2 = os.path.join(f\"{home_directory}{selected_dir}\", name, 'copies_variable.pkl')\n",
        "        file_path_3 = os.path.join(f\"{home_directory}{selected_dir}\", name, 'num_designs_variable.pkl')\n",
        "\n",
        "        with open(file_path_1, 'rb') as file:\n",
        "            contigs = pickle.load(file)\n",
        "            print(f\"Successfully loaded {file_path_1}\")\n",
        "\n",
        "        with open(file_path_2, 'rb') as file:\n",
        "            copies = pickle.load(file)\n",
        "            print(f\"Successfully loaded {file_path_2}\")\n",
        "\n",
        "        with open(file_path_3, 'rb') as file:\n",
        "            num_designs = pickle.load(file)\n",
        "            print(f\"Successfully loaded {file_path_3}\")\n",
        "\n",
        "\n",
        "        path = os.path.join(f\"{home_directory}{selected_dir}\", name)\n",
        "\n",
        "\n",
        "\n",
        "path_without_last_4 = path[:-len(name)]\n",
        "\n",
        "\n",
        "def plot_pdb(num=0):\n",
        "  if denoise:\n",
        "    pdb_traj = f\"{path_without_last_4}traj/{name}_{num}_pX0_traj.pdb\"\n",
        "  else:\n",
        "    pdb_traj = f\"{path_without_last_4}traj/{name}_{num}_Xt-1_traj.pdb\"\n",
        "  if animate in [\"none\",\"interactive\"]:\n",
        "    hbondCutoff = 4.0\n",
        "    view = py3Dmol.view(js='https://3dmol.org/build/3Dmol.js')\n",
        "    if animate == \"interactive\":\n",
        "      pdb_str = open(pdb_traj,'r').read()\n",
        "      view.addModelsAsFrames(pdb_str,'pdb',{'hbondCutoff':hbondCutoff})\n",
        "    else:\n",
        "      pdb = f\"{path}_{num}.pdb\"\n",
        "\n",
        "      pdb_str = open(pdb,'r').read()\n",
        "      view.addModel(pdb_str,'pdb',{'hbondCutoff':hbondCutoff})\n",
        "    if color == \"rainbow\":\n",
        "      view.setStyle({'cartoon': {'color':'spectrum'}})\n",
        "    elif color == \"chain\":\n",
        "      for n,chain,c in zip(range(len(contigs)),\n",
        "                              alphabet_list,\n",
        "                              pymol_color_list):\n",
        "          view.setStyle({'chain':chain},{'cartoon': {'color':c}})\n",
        "    else:\n",
        "      view.setStyle({'cartoon': {'colorscheme': {'prop':'b','gradient': 'roygb','min':0.5,'max':0.9}}})\n",
        "    view.zoomTo()\n",
        "    if animate == \"interactive\":\n",
        "      view.animate({'loop': 'backAndForth'})\n",
        "    view.show()\n",
        "  else:\n",
        "    Ls = get_Ls(contigs)\n",
        "    xyz, bfact = get_ca(pdb_traj, get_bfact=True)\n",
        "    xyz = xyz.reshape((-1,sum(Ls),3))[::-1]\n",
        "    bfact = bfact.reshape((-1,sum(Ls)))[::-1]\n",
        "    if color == \"chain\":\n",
        "      display(HTML(make_animation(xyz, Ls=Ls, dpi=dpi, ref=-1)))\n",
        "    elif color == \"rainbow\":\n",
        "      display(HTML(make_animation(xyz, dpi=dpi, ref=-1)))\n",
        "    else:\n",
        "      display(HTML(make_animation(xyz, plddt=bfact*100, dpi=dpi, ref=-1)))\n",
        "\n",
        "\n",
        "if num_designs > 1:\n",
        "  output = widgets.Output()\n",
        "  def on_change(change):\n",
        "    if change['name'] == 'value':\n",
        "      with output:\n",
        "        output.clear_output(wait=True)\n",
        "        plot_pdb(change['new'])\n",
        "  dropdown = widgets.Dropdown(\n",
        "      options=[(f'{k}',k) for k in range(num_designs)],\n",
        "      value=0, description='design:',\n",
        "  )\n",
        "  dropdown.observe(on_change)\n",
        "  display(widgets.VBox([dropdown, output]))\n",
        "  with output:\n",
        "    plot_pdb(dropdown.value)\n",
        "else:\n",
        "  plot_pdb()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Hacking the script to only check wanted structures {run: \"auto\"}\n",
        "\n",
        "#@markdown #*ATTENTION* This script asks for your input\n",
        "#@markdown Please enter the id of the strucutres that look decent like this: \"1,3,4\"\n",
        "\n",
        "# Define the paths for the original and modified files\n",
        "original_file_path = \"colabdesign/rf/designability_test.py\"\n",
        "modified_file_path = \"colabdesign/rf/designability_test_modified.py\"\n",
        "\n",
        "# Define the new line to replace the old one\n",
        "new_line = \"  for m in m_values:\\n\"  # Note the tab character before 'for'\n",
        "\n",
        "# Read the contents of the original file\n",
        "with open(original_file_path, \"r\") as original_file:\n",
        "    original_content = original_file.readlines()\n",
        "\n",
        "# Modify the line containing the for loop\n",
        "modified_content = []\n",
        "for line in original_content:\n",
        "    if \"for m in range(o.num_designs):\" in line:  # Account for the tab character\n",
        "        modified_content.append(new_line)\n",
        "    else:\n",
        "        modified_content.append(line)\n",
        "\n",
        "# Write the modified contents to the new file\n",
        "with open(modified_file_path, \"w\") as modified_file:\n",
        "    modified_file.writelines(modified_content)\n",
        "\n",
        "# Define the paths for the original and modified files\n",
        "original_file_path = \"colabdesign/rf/designability_test_modified.py\"\n",
        "modified_file_path = \"colabdesign/rf/designability_test_modified.py\"\n",
        "\n",
        "# Define the line to be replaced and the new lines\n",
        "line_to_replace = '  ag.add([\"mpnn_sampling_temp=\" ], 0.1,  float, [\"sampling temperature used by proteinMPNN\"])\\n'\n",
        "new_lines = [\n",
        "    \"  ag.add([\\\"mpnn_sampling_temp=\\\" ], 0.1,  float, [\\\"sampling temperature used by proteinMPNN\\\"])\\n\",\n",
        "    \"  ag.add([\\\"m_str=\\\" ], None,  str, [\\\"samples\\\"])\\n\",\n",
        "    \"  ag.txt(\\\"-------------------------------------------------------------------------------------\\\")\\n\",\n",
        "    \"  o = ag.parse(argv)\\n\",\n",
        "    \"  import sys\\n\",\n",
        "    \"  # Retrieve the values of 'm' from command-line arguments\\n\",\n",
        "    \"  m_values = list(map(int, o.m_str.split('_')))\\n\",\n",
        "    \"  # Now you can use 'm_values' in your script\\n\",\n",
        "    \"  print(\\\"Values of 'm' received:\\\", m_values, o.m_str)\\n\"\n",
        "]\n",
        "\n",
        "# Read the contents of the original file\n",
        "with open(original_file_path, \"r\") as original_file:\n",
        "    original_content = original_file.readlines()\n",
        "\n",
        "# Modify the line containing the specified text\n",
        "modified_content = []\n",
        "for line in original_content:\n",
        "    if line == line_to_replace:  # Check if the line matches the one to be replaced\n",
        "        modified_content.extend(new_lines)  # Append the new lines\n",
        "    else:\n",
        "        modified_content.append(line)\n",
        "\n",
        "# Write the modified contents to the new file\n",
        "with open(modified_file_path, \"w\") as modified_file:\n",
        "    modified_file.writelines(modified_content)\n",
        "\n",
        "print(f\"Modified file created: {modified_file_path}\")\n",
        "\n",
        "# Prompt the user to enter values for mx separated by commas\n",
        "#design_choice_input = input(\"Enter values for mx separated by commas: \")\n",
        "\n",
        "design_choice_input = \"0,3\" # @param {type:\"string\"}\n",
        "\n",
        "# Convert the input string into a list of integers\n",
        "mx = [int(x) for x in design_choice_input.split(',')]\n",
        "\n",
        "# Display the entered values\n",
        "print(\"List of designs to feed into ProteinMPNN and AlphaFold2:\", mx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "8HPrPeRu2cRA",
        "outputId": "8abfcd90-9748-4d6e-eda4-c330a9781be2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modified file created: colabdesign/rf/designability_test_modified.py\n",
            "List of designs to feed into ProteinMPNN and AlphaFold2: [0, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-ikuOyYMgjh",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# @title run **ProteinMPNN** to generate a sequence and **AlphaFold** to validate { display-mode: \"form\" }\n",
        "%%time\n",
        "#@markdown - If more ProteinMPNN results are to be generated with a rerun after a shutdown, check the box\n",
        "#@markdown - Reasons to also check the box: Change RFdiff input directory\n",
        "#@markdown - Leave box unchecked if you are just rerunning ProteinMPNN to get more sequneces during a normal campaign.\n",
        "\n",
        "\n",
        "restarting_after_shutdown = False # @param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "if restarting_after_shutdown:\n",
        "  import pickle\n",
        "  name = \"full_rfdiff_result\"\n",
        "\n",
        "  # Define the drive directory\n",
        "  home_directory = f\"/content/cloud_drive/MyDrive/{home_dir_user}/RFdiff/\"\n",
        "\n",
        "\n",
        "\n",
        "  # Get a list of all directories in the drive directory\n",
        "  all_dirs = [d for d in os.listdir(home_directory) if os.path.isdir(os.path.join(home_directory, d))]\n",
        "\n",
        "  # Display a numbered list of directories\n",
        "  print(\"Available Directories:\")\n",
        "  for i, d in enumerate(all_dirs, 1):\n",
        "        print(f\"[{i}] {d}\")\n",
        "\n",
        "    # Prompt the user to input a number\n",
        "  if not 'selected_number' in globals():\n",
        "    selected_number = input(\"Enter the number of the directory you want to select: \")\n",
        "  try:\n",
        "    if  'selected_number' in globals():\n",
        "      print(f\"Taking the same folder as input that was choose in *Display 3D structure* cell: {path}\")\n",
        "  except ValueError:\n",
        "        print(\"Invalid input.\")\n",
        "\n",
        "    # Validate user input\n",
        "  try:\n",
        "        selected_number = int(selected_number)\n",
        "        if 1 <= selected_number <= len(all_dirs):\n",
        "            selected_dir = all_dirs[selected_number - 1]\n",
        "            print(f\"Selected directory: {selected_dir}\")\n",
        "        else:\n",
        "            print(\"Invalid number. Please enter a valid number.\")\n",
        "  except ValueError:\n",
        "        print(\"Invalid input. Please enter a valid number.\")\n",
        "\n",
        "  file_path_1 = os.path.join(f\"{home_directory}{selected_dir}\", name, 'contig_variable.pkl')\n",
        "  file_path_2 = os.path.join(f\"{home_directory}{selected_dir}\", name, 'copies_variable.pkl')\n",
        "  file_path_3 = os.path.join(f\"{home_directory}{selected_dir}\", name, 'num_designs_variable.pkl')\n",
        "\n",
        "  with open(file_path_1, 'rb') as file:\n",
        "      contigs = pickle.load(file)\n",
        "      print(f\"Successfully loaded {file_path_1}\")\n",
        "\n",
        "  with open(file_path_2, 'rb') as file:\n",
        "      copies = pickle.load(file)\n",
        "      print(f\"Successfully loaded {file_path_2}\")\n",
        "\n",
        "  with open(file_path_3, 'rb') as file:\n",
        "      num_designs = pickle.load(file)\n",
        "      print(f\"Successfully loaded {file_path_3}\")\n",
        "\n",
        "  path = os.path.join(f\"{home_directory}{selected_dir}\", name)\n",
        "\n",
        "if not 'copies' in globals():\n",
        "    print(\"Please tick the restarting_after_shutdown box\")\n",
        "    sys.exit(1)\n",
        "\n",
        "#contigs2 = contigs.replace(\" \", \":\")\n",
        "#print(contigs2)\n",
        "#contigs2 = [f'{contigs2}']\n",
        "\n",
        "\n",
        "#@markdown - I recommend 16\n",
        "num_seqs = 16 #@param [\"1\", \"2\", \"4\", \"8\", \"16\", \"32\", \"64\"] {type:\"raw\"}\n",
        "initial_guess = False\n",
        "\n",
        "#@markdown - Leave at 0, just adjust if necessary and you now why\n",
        "num_recycles = 0 #@param [\"0\", \"1\", \"2\", \"3\", \"6\", \"12\"] {type:\"raw\"}\n",
        "use_multimer = True\n",
        "#@markdown You can exclude certain aminoacids, like Cystein from being used by ProteinMPNN (Disulfidebridge forming)\n",
        "rm_aa = \"C\" #@param {type:\"string\"}\n",
        "#@markdown Higher temperature means higher sequence diversity (0.1 for 8 seq is recommended)\n",
        "mpnn_sampling_temp = 0.1 #@param [\"0.0001\", \"0.1\", \"0.15\", \"0.2\", \"0.25\", \"0.3\", \"0.5\", \"1.0\"] {type:\"raw\"}\n",
        "\n",
        "if not os.path.isfile(\"params/done.txt\"):\n",
        "  print(\"downloading AlphaFold params...\")\n",
        "  while not os.path.isfile(\"params/done.txt\"):\n",
        "    time.sleep(5)\n",
        "\n",
        "cut_of_path = path[:-len(name)]\n",
        "\n",
        "counter = 1\n",
        "\n",
        "while True:\n",
        "    # Generate the directory name with a counter\n",
        "    save_proteinMpnn_results = f\"{cut_of_path}results_proteinMPNN_run_{counter:03d}\"\n",
        "    # Check if the directory already exists\n",
        "    if not os.path.exists(save_proteinMpnn_results):\n",
        "        # If it doesn't exist, create the directory and break out of the loop\n",
        "        os.makedirs(save_proteinMpnn_results)\n",
        "        print(f\"Created result directory: {save_proteinMpnn_results}\")\n",
        "        break\n",
        "    counter += 1\n",
        "\n",
        "# Convert the list 'mx' to a string\n",
        "m_str = '_'.join(map(str, mx))\n",
        "\n",
        "contigs_str = \":\".join(contigs)\n",
        "opts = [f\"--pdb={path}_0.pdb\",\n",
        "        f\"--loc={save_proteinMpnn_results}\",\n",
        "        f\"--contig={contigs_str}\",\n",
        "        f\"--copies={copies}\",\n",
        "        f\"--num_seqs={num_seqs}\",\n",
        "        f\"--num_recycles={num_recycles}\",\n",
        "        f\"--rm_aa={rm_aa}\",\n",
        "        f\"--mpnn_sampling_temp={mpnn_sampling_temp}\",\n",
        "        f\"--num_designs={num_designs}\",\n",
        "        f\"--m_str={m_str}\"]\n",
        "\n",
        "if initial_guess: opts.append(\"--initial_guess\")\n",
        "if use_multimer: opts.append(\"--use_multimer\")\n",
        "opts = ' '.join(opts)\n",
        "!python colabdesign/rf/designability_test_modified.py {opts}\n",
        "\n",
        "\n",
        "delete_their_ranking = f'{save_proteinMpnn_results}/best*'\n",
        "!rm -f $delete_their_ranking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wb_lRRE3MqZH"
      },
      "outputs": [],
      "source": [
        "# @title Filter and Sort results { display-mode: \"form\" }\n",
        "\n",
        "#@markdown Best new binders (if there are any) are found in the \"best_binders_redesignes\" directory. If ProteinMPNN run multiple time (recommended to generate more condidates) the best binders are collected in the \"All_top_binders_redesigns\" directory. In both directories you will also find a csv called \"info_table_***.csv\" with the relevant scores (rounded) and sequences of the best binders.\n",
        "\n",
        "result_csv_path = os.path.join(save_proteinMpnn_results,\"mpnn_results.csv\")\n",
        "\n",
        "print(f\"Full result file can be found at: {result_csv_path}\")\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file into a pandas DataFrame\n",
        "df = pd.read_csv(result_csv_path)\n",
        "if 1 == 1:\n",
        "  df[['target','binder']] = df['seq'].str.split('/', expand=True)\n",
        "\n",
        "  # Drop the original \"seq\" column if needed\n",
        "  df = df.drop('seq', axis=1)\n",
        "\n",
        "  df = df.sort_values(by='i_pae')\n",
        "\n",
        "\n",
        "  #@markdown ### Set Thresholds\n",
        "  #@markdown - `plddt`: Pre-set threshold **>= 0.85** *How secure is AF2 that the binder sequence folds like this? Higher = more secure, > 0.9 perfect, 0.8 - 0.7 medium, < 0.6 highly insecure*\n",
        "  #@markdown - `i_pae`: Pre-set threshold **<= 11** *Interaction score, how sure is AF2 that binder:target interact like this?*\n",
        "  #@markdown - `rmsd`: Pre-set threshold **<= 10** *Difference between RFdiff binder model and ProteinMPNN+AF2 binder, the higher the more different it is from the binder structure (high rmsd + very low i_pae could be interesting (write me->Noah)*\n",
        "  #@markdown - `i_ptm`: Pre-set threshold **>= 0.45** *Interaction score, correlates strong with i_pae but is more restrictive*\n",
        "  #@markdown ***\n",
        "  #@markdown ### Explorer mode options\n",
        "  #@markdown - Explore mode should be turned on if the preset setting has not revealed a binder and you want to relax the thesholds **(Not recommended, only use if you know the consequences)**\n",
        "  Explore_mode = False #@param {type:\"boolean\"}\n",
        "  #@markdown - If values are changed without Explorer mode \"ON\", this will NOT affect the analysis\n",
        "  plddt_threshold = 0.85\n",
        "  i_pae_threshold = 11\n",
        "  rmsd_threshold = 10\n",
        "  i_ptm_threshold = 0.45\n",
        "\n",
        "  if Explore_mode:\n",
        "    # Set threshold values\n",
        "    plddt_threshold = 0.2 #@param {type:\"number\"}\n",
        "    i_pae_threshold = 27 #@param {type:\"number\"}\n",
        "    rmsd_threshold = 70 #@param {type:\"number\"}\n",
        "    i_ptm_threshold = 0.03 #@param {type:\"number\"}\n",
        "\n",
        "  #@markdown ***\n",
        "  # Assuming df is your DataFrame\n",
        "  filtered_df = df[\n",
        "      (df['plddt'] > plddt_threshold) &\n",
        "      (df['i_pae'] < i_pae_threshold) &\n",
        "      (df['rmsd'] < rmsd_threshold) &\n",
        "      (df['i_ptm'] > i_ptm_threshold)\n",
        "  ].copy()\n",
        "\n",
        "\n",
        "  columns_to_round = ['mpnn', 'plddt', 'i_ptm', 'i_pae', 'rmsd']\n",
        "\n",
        "  # Iterate over the specified columns and round the values to two decimal places\n",
        "  for column in columns_to_round:\n",
        "      filtered_df.loc[:, column] = filtered_df[column].round(2)\n",
        "  # Add run info to frame\n",
        "  name_run = save_proteinMpnn_results[-19:]\n",
        "\n",
        "  filtered_df['Unnamed: 0'] = filtered_df['Unnamed: 0'].replace(to_replace=df['Unnamed: 0'].unique(), value=name_run)\n",
        "  # Assuming df is your DataFrame\n",
        "  filtered_df.rename(columns={'Unnamed: 0': 'run_name'}, inplace=True)\n",
        "\n",
        "  #Best pdb target directories\n",
        "  destination_dir = f'{save_proteinMpnn_results}/best_binder_redesigns'\n",
        "  destination_dir_allstars = f'{cut_of_path}/All_top_binder_redesigns'\n",
        "\n",
        "\n",
        "  os.makedirs(destination_dir, exist_ok=True)\n",
        "  cut_of_path = path[:-len(name)]\n",
        "  os.makedirs(destination_dir_allstars, exist_ok=True)\n",
        "\n",
        "  import pandas as pd\n",
        "  import shutil\n",
        "\n",
        "\n",
        "  if filtered_df.empty:\n",
        "    sys.exit(\"No good binder was found! Please rerun ProteinMPNN with more sequences, optionally set recycle = 1 or if all this doesnt help, rerun the RFdiff step with num_designs = 16. Worst case, your input just does not work well with partial diff.\")\n",
        "\n",
        "  # Iterate over the DataFrame rows\n",
        "  for index, row in filtered_df.iterrows():\n",
        "      design = row['design']\n",
        "      n = row['n']\n",
        "      mpnn = row['mpnn']\n",
        "      plddt = row['plddt']\n",
        "      i_ptm = row['i_ptm']\n",
        "      i_pae = row['i_pae']\n",
        "      rmsd = row['rmsd']\n",
        "      target = row['target']\n",
        "      binder = row['binder']\n",
        "\n",
        "      # Assuming the file name is a combination of design, n, and target\n",
        "      source_file_path = f'{save_proteinMpnn_results}/all_pdb/design{design}_n{n}.pdb'\n",
        "\n",
        "      name_run = save_proteinMpnn_results[-19:]\n",
        "\n",
        "      # Construct the full paths for destination\n",
        "\n",
        "      destination_file_name = f'{name_run}_design{design}_n{n}_i-pae_{i_pae}_rmsd_{rmsd}.pdb'\n",
        "\n",
        "      destination_path_name = os.path.join(destination_dir, destination_file_name)\n",
        "\n",
        "      # Use shutil.copy to copy the file\n",
        "      shutil.copy(source_file_path, destination_path_name)\n",
        "\n",
        "\n",
        "      ## Collecting all the best binders in a single directory\n",
        "      destination_path_name_allstars = os.path.join(destination_dir_allstars, destination_file_name)\n",
        "      # Use shutil.copy to copy the file to the allstars folder\n",
        "      shutil.copy(source_file_path, destination_path_name_allstars)\n",
        "\n",
        "  # Specify the path where you want to save the CSV file\n",
        "  destination_csv_name = f'info_table_best_binder_redesigns_{name_run}.csv'\n",
        "\n",
        "  destination_path_name_csv = os.path.join(destination_dir, destination_csv_name)\n",
        "\n",
        "  # Write the DataFrame to a CSV file\n",
        "  filtered_df.to_csv(destination_path_name_csv, index=False)\n",
        "\n",
        "  # Specify the path where you want to save the CSV file\n",
        "  destination_csv_name_allstar = f'info_table_best_binder_redesigns_allstars.csv'\n",
        "  destination_path_name_csv_allstar = os.path.join(destination_dir_allstars, destination_csv_name_allstar)\n",
        "\n",
        "  if os.path.exists(destination_path_name_csv_allstar):\n",
        "      # Append the DataFrame to the existing CSV file\n",
        "      filtered_df.to_csv(destination_path_name_csv_allstar, mode='a', header=False, index=False)\n",
        "  else:\n",
        "      # Create the DataFrame to the existing CSV file\n",
        "      filtered_df.to_csv(destination_path_name_csv_allstar, header=True, index=False)\n",
        "\n",
        "  # Read the CSV file into a pandas DataFrame\n",
        "  df_allstars = pd.read_csv(destination_path_name_csv_allstar)\n",
        "\n",
        "  # Remove duplicate rows based on all columns\n",
        "  df_allstars = df_allstars.drop_duplicates()\n",
        "\n",
        "  # Overwrite the original CSV file with the cleaned DataFrame\n",
        "  df_allstars.to_csv(destination_path_name_csv_allstar, header=True, index=False)\n",
        "\n",
        "  # Display the filtered DataFrame\n",
        "  print(\"These are the best hits in this run fulfilling all minimal criteria of a good binder:target pair. Metrics are rounded\")\n",
        "  print(filtered_df.iloc[:, :8].sort_values(by='i_pae'))\n",
        "\n",
        "  print('##################################################################################')\n",
        "\n",
        "\n",
        "  print(\"These are the best hits in ALL runs fulfilling all minimal criteria of a good binder:target pair. Metrics are rounded\")\n",
        "  df_allstars.sort_values(by='i_pae')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fyKZ54bZDC0U"
      },
      "outputs": [],
      "source": [
        "# @title Display best result and save notebook copy{ display-mode: \"form\" }\n",
        "# @markdown MUST run this cell, saves copy of the noteboook to your result folder { display-mode: \"form\" }\n",
        "#@markdown - **Highly Recommended** for Reproducibility\n",
        "\n",
        "#@markdown Personal flavour edition result presentation\n",
        "import os\n",
        "import py3Dmol\n",
        "import ipywidgets as widgets\n",
        "\n",
        "def plot_pdb(pdb):\n",
        "    print(pdb)\n",
        "    hbondCutoff = 4.0\n",
        "    cut_of_path = path[:-len(name)]\n",
        "    numer_of_rfdiff_design = pdb[26:27]\n",
        "\n",
        "    view = py3Dmol.view(js='https://3dmol.org/build/3Dmol.js')\n",
        "    pdb_str = open(f\"{best_binder_path}/{pdb}\", 'r').read()\n",
        "    view.addModel(pdb_str, 'pdb', {'hbondCutoff': hbondCutoff})\n",
        "    pdb_str_2 = open(f\"{cut_of_path}{name}_{numer_of_rfdiff_design}.pdb\",'r').read()\n",
        "    view.addModel(pdb_str_2,'pdb',{'hbondCutoff':hbondCutoff})\n",
        "\n",
        "    view.setStyle({\"model\":1},{'cartoon':{}}) #: {'colorscheme': {'prop':'b','gradient': 'roygb','min':0,'max':100}}})\n",
        "    view.setStyle({\"model\":0},{'cartoon':{'colorscheme': {'prop':'b','gradient': 'roygb','min':0,'max':100}}})\n",
        "    view.zoomTo()\n",
        "    view.show()\n",
        "try:\n",
        "  best_binder_path = destination_dir\n",
        "  pdb_files = [f for f in os.listdir(best_binder_path) if f.endswith('.pdb')]\n",
        "\n",
        "  if len(pdb_files) > 1:\n",
        "      dropdown = widgets.Dropdown(\n",
        "          options=pdb_files,\n",
        "          value=pdb_files[0],\n",
        "          description='Select a pdb file:',\n",
        "      )\n",
        "      output = widgets.Output()\n",
        "      display(widgets.VBox([dropdown, output]))\n",
        "\n",
        "      with output:\n",
        "          plot_pdb(dropdown.value)\n",
        "\n",
        "      def on_change(change):\n",
        "          if change['name'] == 'value':\n",
        "              with output:\n",
        "                  output.clear_output(wait=True)\n",
        "                  plot_pdb(change['new'])\n",
        "\n",
        "      dropdown.observe(on_change)\n",
        "  else:\n",
        "      plot_pdb(pdb_files[0])\n",
        "except:\n",
        "  print(\"Display of normal RFdiff results is not supported yet, only 3DDiff Binder design\")\n",
        "\n",
        "if not local_run:\n",
        "  import shutil\n",
        "\n",
        "  # Define the source and destination paths\n",
        "  source_path = '/content/cloud_drive/MyDrive/Colab Notebooks/Selective_RFdiff_with_Backup.ipynb'\n",
        "  destination_directory = save_proteinMpnn_results  # Assuming jobname is the variable containing the directory path\n",
        "\n",
        "  # Specify the destination path\n",
        "  destination_path = os.path.join(destination_directory, f'Selective_RFdiff_with_Backup_for_{project_directory_name}.ipynb')\n",
        "\n",
        "  # Copy the file\n",
        "  shutil.copy(source_path, destination_path)\n",
        "  print(f\"Sucessfullly saved a copy at {destination_path}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKQXlWEjIOsf"
      },
      "source": [
        "**Instructions**\n",
        "---\n",
        "---\n",
        "\n",
        "Use `contigs` to define continious chains. Use a `:` to define multiple contigs and a `/` to define mutliple segments within a contig.\n",
        "For example:\n",
        "\n",
        "\n",
        "**binder design**\n",
        "- `contigs='A:50'` `pdb='4N5T'` - diffuse a **binder** of length 50 to chain A of defined PDB.\n",
        "- `contigs='E6-155:70-100'` `pdb='5KQV'` `hotspot='E64,E88,E96'` - diffuse a **binder** of length 70 to 100 (sampled randomly) to chain E and defined hotspot(s).\n",
        "\n",
        "*hints and tips*\n",
        "- `pdb=''` leave blank to get an upload prompt\n",
        "- `contigs='50-100'` use dash to specify a range of lengths to sample from"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}